{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.6.0\n",
      "CUDA Available: False\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading Data ---\n",
      "CSV files loaded into Pandas DataFrames successfully.\n",
      "\n",
      "--- 2. Inspecting DataFrames (Raw) ---\n",
      "x_train_df shape: (60000, 784)\n",
      "y_train_df shape: (60000, 1)\n",
      "x_test_df shape: (10000, 784)\n",
      "y_test_df shape: (10000, 1)\n",
      "\n",
      "x_train_df Head:\n",
      "   0  1  2  3  4  5  6  7  8   9  ...  774  775  776  777  778  779  780  781  \\\n",
      "0  0  0  0  0  0  0  0  0  0   0  ...    0    0    0    0    0    0    0    0   \n",
      "1  0  0  0  0  0  1  0  0  0   0  ...  119  114  130   76    0    0    0    0   \n",
      "2  0  0  0  0  0  0  0  0  0  22  ...    0    0    1    0    0    0    0    0   \n",
      "\n",
      "   782  783  \n",
      "0    0    0  \n",
      "1    0    0  \n",
      "2    0    0  \n",
      "\n",
      "[3 rows x 784 columns]\n",
      "\n",
      "y_train_df Head:\n",
      "   0\n",
      "0  1\n",
      "1  2\n",
      "2  2\n",
      "\n",
      "Value Counts for column '0' in y_train_df:\n",
      "0\n",
      "0     6000\n",
      "1    12000\n",
      "2    30000\n",
      "3     6000\n",
      "4     6000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "NaN values check:\n",
      "  x_train: 0\n",
      "  y_train: 0\n",
      "  x_test: 0\n",
      "  y_test: 0\n",
      "\n",
      "DataFrame shapes and basic content look correct.\n",
      "\n",
      "--- 3. Converting, Reshaping, Normalizing ---\n",
      "Data converted to Tensors, reshaped, and normalized.\n",
      "\n",
      "--- 4. Verifying Processed Tensors ---\n",
      "Tensor shapes are correct.\n",
      "\n",
      "--- Data Loading and Preprocessing Complete ---\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_DIR = 'data/'\n",
    "X_TRAIN_PATH = os.path.join(DATA_DIR, 'x_train.csv')\n",
    "Y_TRAIN_PATH = os.path.join(DATA_DIR, 'y_train.csv')\n",
    "X_TEST_PATH = os.path.join(DATA_DIR, 'x_test.csv')\n",
    "Y_TEST_PATH = os.path.join(DATA_DIR, 'y_test.csv')\n",
    "\n",
    "EXPECTED_TRAIN_SAMPLES = 60000\n",
    "EXPECTED_TEST_SAMPLES = 10000\n",
    "EXPECTED_FEATURES = 784\n",
    "EXPECTED_IMG_SHAPE_TENSOR = (1, 28, 28) # (C, H, W)\n",
    "EXPECTED_LABEL_CLASSES = 5\n",
    "\n",
    "print(\"--- 1. Loading Data ---\")\n",
    "try:\n",
    "    x_train_df = pd.read_csv(X_TRAIN_PATH)\n",
    "    y_train_df = pd.read_csv(Y_TRAIN_PATH)\n",
    "    x_test_df = pd.read_csv(X_TEST_PATH)\n",
    "    y_test_df = pd.read_csv(Y_TEST_PATH)\n",
    "    print(\"CSV files loaded into Pandas DataFrames successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV files: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n--- 2. Inspecting DataFrames (Raw) ---\")\n",
    "print(f\"x_train_df shape: {x_train_df.shape}\")\n",
    "print(f\"y_train_df shape: {y_train_df.shape}\")\n",
    "print(f\"x_test_df shape: {x_test_df.shape}\")\n",
    "print(f\"y_test_df shape: {y_test_df.shape}\")\n",
    "\n",
    "\n",
    "print(\"\\nx_train_df Head:\")\n",
    "print(x_train_df.head(3))\n",
    "print(\"\\ny_train_df Head:\")\n",
    "print(y_train_df.head(3))\n",
    "\n",
    "label_col_name = y_train_df.columns[0]\n",
    "print(f\"\\nValue Counts for column '{label_col_name}' in y_train_df:\")\n",
    "print(y_train_df[label_col_name].value_counts().sort_index())\n",
    "\n",
    "# Check for NaN values\n",
    "print(f\"\\nNaN values check:\")\n",
    "print(f\"  x_train: {x_train_df.isnull().sum().sum()}\")\n",
    "print(f\"  y_train: {y_train_df.isnull().sum().sum()}\")\n",
    "print(f\"  x_test: {x_test_df.isnull().sum().sum()}\")\n",
    "print(f\"  y_test: {y_test_df.isnull().sum().sum()}\")\n",
    "\n",
    "# Verify shapes match expectations (rows)\n",
    "assert x_train_df.shape[0] == EXPECTED_TRAIN_SAMPLES, f\"Unexpected number of rows in x_train_df\"\n",
    "assert y_train_df.shape[0] == EXPECTED_TRAIN_SAMPLES, f\"Unexpected number of rows in y_train_df\"\n",
    "assert x_test_df.shape[0] == EXPECTED_TEST_SAMPLES, f\"Unexpected number of rows in x_test_df\"\n",
    "assert y_test_df.shape[0] == EXPECTED_TEST_SAMPLES, f\"Unexpected number of rows in y_test_df\"\n",
    "# Verify features/columns\n",
    "assert x_train_df.shape[1] == EXPECTED_FEATURES, f\"Unexpected number of columns in x_train_df\"\n",
    "assert x_test_df.shape[1] == EXPECTED_FEATURES, f\"Unexpected number of columns in x_test_df\"\n",
    "assert y_train_df.shape[1] == 1, f\"Unexpected number of columns in y_train_df\"\n",
    "assert y_test_df.shape[1] == 1, f\"Unexpected number of columns in y_test_df\"\n",
    "\n",
    "print(\"\\nDataFrame shapes and basic content look correct.\")\n",
    "\n",
    "print(\"\\n--- 3. Converting, Reshaping, Normalizing ---\")\n",
    "x_train_np = x_train_df.values\n",
    "y_train_np = y_train_df.values.squeeze()\n",
    "x_test_np = x_test_df.values\n",
    "y_test_np = y_test_df.values.squeeze()\n",
    "\n",
    "x_train_tensor = torch.from_numpy(x_train_np).float()\n",
    "y_train_tensor = torch.from_numpy(y_train_np).long()\n",
    "x_test_tensor = torch.from_numpy(x_test_np).float()\n",
    "y_test_tensor = torch.from_numpy(y_test_np).long()\n",
    "\n",
    "# Reshape image data for CNNs\n",
    "# (N, C, H, W)\n",
    "x_train_tensor = x_train_tensor.reshape(-1, *EXPECTED_IMG_SHAPE_TENSOR) # (N, 1, 28, 28)\n",
    "x_test_tensor = x_test_tensor.reshape(-1, *EXPECTED_IMG_SHAPE_TENSOR)  # (N, 1, 28, 28)\n",
    "\n",
    "# Normalize pixel values\n",
    "# Scale pixel values from [0, 255] to [0, 1]\n",
    "x_train_tensor = x_train_tensor / 255.0\n",
    "x_test_tensor = x_test_tensor / 255.0\n",
    "\n",
    "print(\"Data converted to Tensors, reshaped, and normalized.\")\n",
    "\n",
    "print(\"\\n--- 4. Verifying Processed Tensors ---\")\n",
    "assert x_train_tensor.shape == (EXPECTED_TRAIN_SAMPLES, *EXPECTED_IMG_SHAPE_TENSOR), \\\n",
    "    f\"x_train_tensor shape mismatch: Expected {(EXPECTED_TRAIN_SAMPLES, *EXPECTED_IMG_SHAPE_TENSOR)}, Got {x_train_tensor.shape}\"\n",
    "assert y_train_tensor.shape == (EXPECTED_TRAIN_SAMPLES,), \\\n",
    "    f\"y_train_tensor shape mismatch: Expected {(EXPECTED_TRAIN_SAMPLES,)}, Got {y_train_tensor.shape}\"\n",
    "assert x_test_tensor.shape == (EXPECTED_TEST_SAMPLES, *EXPECTED_IMG_SHAPE_TENSOR), \\\n",
    "    f\"x_test_tensor shape mismatch: Expected {(EXPECTED_TEST_SAMPLES, *EXPECTED_IMG_SHAPE_TENSOR)}, Got {x_test_tensor.shape}\"\n",
    "assert y_test_tensor.shape == (EXPECTED_TEST_SAMPLES,), \\\n",
    "    f\"y_test_tensor shape mismatch: Expected {(EXPECTED_TEST_SAMPLES,)}, Got {y_test_tensor.shape}\"\n",
    "print(\"Tensor shapes are correct.\")\n",
    "\n",
    "print(\"\\n--- Data Loading and Preprocessing Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying random samples from the training set...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x250 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_images(dataset, labels, n_samples=10, title_prefix=\"\"):\n",
    "    \"\"\"Displays n_samples random images from the dataset.\"\"\"\n",
    "    plt.figure(figsize=(n_samples * 1.2, 2.5)) # Adjust figure size based on number of samples\n",
    "    indices = np.random.choice(len(dataset), n_samples, replace=False)\n",
    "    for i, idx in enumerate(indices):\n",
    "        img = dataset[idx]      # Shape (1, 28, 28)\n",
    "        label = labels[idx].item() # Get scalar value from tensor\n",
    "\n",
    "        img_display = img.squeeze().cpu().numpy()\n",
    "\n",
    "        plt.subplot(1, n_samples, i + 1)\n",
    "        plt.imshow(img_display, cmap='gray')\n",
    "        plt.title(f\"Label: {label}\")\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(f\"{title_prefix}{n_samples} Random Training Samples\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Displaying random samples from the training set...\")\n",
    "show_images(x_train_tensor, y_train_tensor, n_samples=12, title_prefix=\"Train: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created TensorDatasets:\n",
      "  Full training set size: 60000\n",
      "  Test set size: 10000\n",
      "\n",
      "Split training data:\n",
      "  Training subset size: 48000\n",
      "  Validation subset size: 12000\n",
      "\n",
      "Created DataLoaders:\n",
      "  Train loader: 750 batches of size 64\n",
      "  Validation loader: 188 batches of size 64\n",
      "  Test loader: 157 batches of size 64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "\n",
    "# --- Hyperparameters for Data Loading ---\n",
    "VALIDATION_SPLIT = 0.2 # Use 20% of the training data for validation\n",
    "BATCH_SIZE = 64        # Batch size for training and evaluation\n",
    "\n",
    "\n",
    "full_train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "print(f\"Created TensorDatasets:\")\n",
    "print(f\"  Full training set size: {len(full_train_dataset)}\")\n",
    "print(f\"  Test set size: {len(test_dataset)}\")\n",
    "\n",
    "\n",
    "num_train_samples = len(full_train_dataset)\n",
    "num_val_samples = int(VALIDATION_SPLIT * num_train_samples)\n",
    "num_train_split = num_train_samples - num_val_samples\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_train_dataset,\n",
    "    [num_train_split, num_val_samples],\n",
    "    generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "\n",
    "print(f\"\\nSplit training data:\")\n",
    "print(f\"  Training subset size: {len(train_dataset)}\")\n",
    "print(f\"  Validation subset size: {len(val_dataset)}\")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"\\nCreated DataLoaders:\")\n",
    "print(f\"  Train loader: {len(train_loader)} batches of size {BATCH_SIZE}\")\n",
    "print(f\"  Validation loader: {len(val_loader)} batches of size {BATCH_SIZE}\")\n",
    "print(f\"  Test loader: {len(test_loader)} batches of size {BATCH_SIZE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 - Default Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Q1 Default CNN Architecture ---\n",
      "DefaultCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=6272, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=5, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "         MaxPool2d-2           [-1, 32, 14, 14]               0\n",
      "            Conv2d-3           [-1, 32, 14, 14]           9,248\n",
      "            Linear-4                  [-1, 512]       3,211,776\n",
      "            Linear-5                    [-1, 5]           2,565\n",
      "================================================================\n",
      "Total params: 3,223,909\n",
      "Trainable params: 3,223,909\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.29\n",
      "Params size (MB): 12.30\n",
      "Estimated Total Size (MB): 12.59\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DefaultCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(DefaultCNN, self).__init__()\n",
    "        # Layer 1: Conv -> ReLU -> MaxPool\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        # Input: (N, 1, 28, 28)\n",
    "        # Conv1 Output: (N, 32, 28, 28) (Padding keeps size same: 28 - 3 + 2*1 + 1 = 28)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Pool1 Output: (N, 32, 14, 14) (28 / 2 = 14)\n",
    "\n",
    "        # Layer 2: Conv -> ReLU\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        # Input: (N, 32, 14, 14)\n",
    "        # Conv2 Output: (N, 32, 14, 14) (Padding keeps size same: 14 - 3 + 2*1 + 1 = 14)\n",
    "\n",
    "        # Dense Layers\n",
    "        # Output of conv2 is (N, 32, 14, 14)\n",
    "        self.flattened_size = 32 * 14 * 14\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Dense Layers\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "q1_model = DefaultCNN(num_classes=EXPECTED_LABEL_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_q1 = optim.SGD(q1_model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "print(\"--- Q1 Default CNN Architecture ---\")\n",
    "print(q1_model)\n",
    "\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "    # Provide the input shape (C, H, W) excluding the batch dimension\n",
    "    summary(q1_model, input_size=EXPECTED_IMG_SHAPE_TENSOR, device=device.type)\n",
    "except ImportError:\n",
    "    print(\"\\n'torchsummary' not found. Skipping detailed summary.\")\n",
    "    print(f\"Model has {sum(p.numel() for p in q1_model.parameters() if p.requires_grad):,} trainable parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training DefaultCNN_Q1 for 15 epochs ---\n",
      "Device: cpu\n",
      "Optimizer: SGD (LR=0.01)\n",
      "Batch size: 64\n",
      "Train samples: 48000, Val samples: 12000\n",
      "Epoch 1/15 | Train Loss: 0.2187, Train Acc: 0.9245 (14.42s) | Val Loss: 0.1141, Val Acc: 0.9638 (2.14s)\n",
      "Epoch 2/15 | Train Loss: 0.0899, Train Acc: 0.9726 (14.19s) | Val Loss: 0.0890, Val Acc: 0.9712 (1.89s)\n",
      "Epoch 3/15 | Train Loss: 0.0727, Train Acc: 0.9771 (13.01s) | Val Loss: 0.0846, Val Acc: 0.9732 (1.93s)\n",
      "Epoch 4/15 | Train Loss: 0.0603, Train Acc: 0.9805 (12.83s) | Val Loss: 0.0691, Val Acc: 0.9769 (1.87s)\n",
      "Epoch 5/15 | Train Loss: 0.0518, Train Acc: 0.9826 (14.16s) | Val Loss: 0.0585, Val Acc: 0.9802 (2.07s)\n",
      "Epoch 6/15 | Train Loss: 0.0455, Train Acc: 0.9850 (14.40s) | Val Loss: 0.0598, Val Acc: 0.9784 (2.14s)\n",
      "Epoch 7/15 | Train Loss: 0.0408, Train Acc: 0.9861 (13.44s) | Val Loss: 0.0550, Val Acc: 0.9795 (1.84s)\n",
      "Epoch 8/15 | Train Loss: 0.0357, Train Acc: 0.9877 (12.87s) | Val Loss: 0.0523, Val Acc: 0.9825 (2.53s)\n",
      "Epoch 9/15 | Train Loss: 0.0321, Train Acc: 0.9890 (13.08s) | Val Loss: 0.0514, Val Acc: 0.9835 (1.90s)\n",
      "Epoch 10/15 | Train Loss: 0.0284, Train Acc: 0.9904 (12.56s) | Val Loss: 0.0471, Val Acc: 0.9837 (2.21s)\n",
      "Epoch 11/15 | Train Loss: 0.0256, Train Acc: 0.9913 (13.22s) | Val Loss: 0.0478, Val Acc: 0.9846 (2.08s)\n",
      "Epoch 12/15 | Train Loss: 0.0232, Train Acc: 0.9921 (12.90s) | Val Loss: 0.0488, Val Acc: 0.9838 (1.97s)\n",
      "Epoch 13/15 | Train Loss: 0.0208, Train Acc: 0.9929 (14.78s) | Val Loss: 0.0492, Val Acc: 0.9838 (2.11s)\n",
      "Epoch 14/15 | Train Loss: 0.0197, Train Acc: 0.9928 (13.72s) | Val Loss: 0.0470, Val Acc: 0.9846 (2.04s)\n",
      "Epoch 15/15 | Train Loss: 0.0176, Train Acc: 0.9938 (13.56s) | Val Loss: 0.0497, Val Acc: 0.9858 (2.18s)\n",
      "\n",
      "--- Training Finished ---\n",
      "Total Training Time (DefaultCNN_Q1): 234.05s\n",
      "Average Epoch Time (DefaultCNN_Q1): 15.60s\n",
      "\n",
      "--- Evaluating DefaultCNN_Q1 on Test Set ---\n",
      "Test Loss (DefaultCNN_Q1): 0.0515\n",
      "Test Accuracy (DefaultCNN_Q1): 0.9844\n",
      "Test Evaluation Time (DefaultCNN_Q1): 1.78s\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluation Functions\n",
    "\n",
    "import time\n",
    "\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Trains the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward Pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward Pass and Optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted_labels = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted_labels == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions / total_samples\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_time\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \"\"\"Evaluates the model on a given dataset.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward Pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            correct_predictions += (predicted_labels == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    eval_time = time.time() - start_time\n",
    "    eval_loss = running_loss / total_samples\n",
    "    eval_acc = correct_predictions / total_samples\n",
    "\n",
    "    return eval_loss, eval_acc, eval_time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training Hyperparameters\n",
    "NUM_EPOCHS_Q1 = 15\n",
    "MODEL_NAME_Q1 = \"DefaultCNN_Q1\"\n",
    "\n",
    "print(f\"--- Training {MODEL_NAME_Q1} for {NUM_EPOCHS_Q1} epochs ---\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Optimizer: {type(optimizer_q1).__name__} (LR={optimizer_q1.defaults['lr']})\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")\n",
    "\n",
    "# --- History Tracking ---\n",
    "history_q1 = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'epoch_time': []\n",
    "}\n",
    "\n",
    "total_train_start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS_Q1):\n",
    "    train_loss, train_acc, train_time = train_one_epoch(\n",
    "        q1_model, train_loader, criterion, optimizer_q1, device\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc, val_time = evaluate(\n",
    "        q1_model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    # Record history\n",
    "    history_q1['train_loss'].append(train_loss)\n",
    "    history_q1['train_acc'].append(train_acc)\n",
    "    history_q1['val_loss'].append(val_loss)\n",
    "    history_q1['val_acc'].append(val_acc)\n",
    "    history_q1['epoch_time'].append(train_time + val_time)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS_Q1} | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} ({train_time:.2f}s) | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} ({val_time:.2f}s)\")\n",
    "\n",
    "total_train_end_time = time.time()\n",
    "total_training_time_q1 = total_train_end_time - total_train_start_time\n",
    "avg_epoch_time_q1 = sum(history_q1['epoch_time']) / NUM_EPOCHS_Q1\n",
    "\n",
    "print(f\"\\n--- Training Finished ---\")\n",
    "print(f\"Total Training Time ({MODEL_NAME_Q1}): {total_training_time_q1:.2f}s\")\n",
    "print(f\"Average Epoch Time ({MODEL_NAME_Q1}): {avg_epoch_time_q1:.2f}s\")\n",
    "\n",
    "# --- Evaluate Final Model on Test Set ---\n",
    "print(f\"\\n--- Evaluating {MODEL_NAME_Q1} on Test Set ---\")\n",
    "test_loss_q1, test_acc_q1, test_time_q1 = evaluate(\n",
    "    q1_model, test_loader, criterion, device\n",
    ")\n",
    "print(f\"Test Loss ({MODEL_NAME_Q1}): {test_loss_q1:.4f}\")\n",
    "print(f\"Test Accuracy ({MODEL_NAME_Q1}): {test_acc_q1:.4f}\")\n",
    "print(f\"Test Evaluation Time ({MODEL_NAME_Q1}): {test_time_q1:.2f}s\")\n",
    "\n",
    "# Store test results\n",
    "history_q1['test_loss'] = test_loss_q1\n",
    "history_q1['test_acc'] = test_acc_q1\n",
    "history_q1['test_time'] = test_time_q1\n",
    "history_q1['total_train_time'] = total_training_time_q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 - Improved Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Q2 Improved CNN Architecture ---\n",
      "ImprovedCNN(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=3136, out_features=512, bias=True)\n",
      "  (bn3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=512, out_features=5, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "       BatchNorm2d-2           [-1, 32, 28, 28]              64\n",
      "         MaxPool2d-3           [-1, 32, 14, 14]               0\n",
      "            Conv2d-4           [-1, 64, 14, 14]          18,496\n",
      "       BatchNorm2d-5           [-1, 64, 14, 14]             128\n",
      "         MaxPool2d-6             [-1, 64, 7, 7]               0\n",
      "            Linear-7                  [-1, 512]       1,606,144\n",
      "       BatchNorm1d-8                  [-1, 512]           1,024\n",
      "           Dropout-9                  [-1, 512]               0\n",
      "           Linear-10                    [-1, 5]           2,565\n",
      "================================================================\n",
      "Total params: 1,628,741\n",
      "Trainable params: 1,628,741\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.66\n",
      "Params size (MB): 6.21\n",
      "Estimated Total Size (MB): 6.87\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ImprovedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5, dropout_rate=0.5):\n",
    "        super(ImprovedCNN, self).__init__()\n",
    "        # Layer 1: Conv -> BN -> ReLU -> MaxPool\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Input: (N, 1, 28, 28) -> Conv1: (N, 32, 28, 28) -> BN1 -> ReLU -> Pool1: (N, 32, 14, 14)\n",
    "\n",
    "        # Layer 2: Conv -> BN -> ReLU -> MaxPool\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64) # Batch Norm after Conv2\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # Input: (N, 32, 14, 14) -> Conv2: (N, 64, 14, 14) -> BN2 -> ReLU -> Pool2: (N, 64, 7, 7)\n",
    "\n",
    "        self.flattened_size = 64 * 7 * 7\n",
    "\n",
    "        # Dense Layers\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 512)\n",
    "        self.bn3 = nn.BatchNorm1d(512)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Dense Layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "q2_model = ImprovedCNN(num_classes=EXPECTED_LABEL_CLASSES, dropout_rate=0.5).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_q2 = optim.Adam(q2_model.parameters(), lr=0.001) # Using Adam optimizer\n",
    "\n",
    "print(\"--- Q2 Improved CNN Architecture ---\")\n",
    "print(q2_model)\n",
    "\n",
    "\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "    summary(q2_model, input_size=EXPECTED_IMG_SHAPE_TENSOR, device=device.type)\n",
    "except ImportError:\n",
    "    print(\"\\n'torchsummary' not found. Skipping detailed summary.\")\n",
    "    print(f\"Model has {sum(p.numel() for p in q2_model.parameters() if p.requires_grad):,} trainable parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training ImprovedCNN_Q2 for 15 epochs ---\n",
      "Device: cpu\n",
      "Optimizer: Adam (LR=0.001)\n",
      "Batch size: 64\n",
      "Train samples: 48000, Val samples: 12000\n",
      "Dropout rate: 0.5\n",
      "Epoch 1/15 | Train Loss: 0.0953, Train Acc: 0.9688 (16.94s) | Val Loss: 0.0579, Val Acc: 0.9800 (2.39s)\n",
      "Epoch 2/15 | Train Loss: 0.0530, Train Acc: 0.9824 (17.51s) | Val Loss: 0.0520, Val Acc: 0.9820 (2.20s)\n",
      "Epoch 3/15 | Train Loss: 0.0407, Train Acc: 0.9854 (18.17s) | Val Loss: 0.0439, Val Acc: 0.9854 (2.39s)\n",
      "Epoch 4/15 | Train Loss: 0.0324, Train Acc: 0.9883 (15.86s) | Val Loss: 0.0430, Val Acc: 0.9859 (2.27s)\n",
      "Epoch 5/15 | Train Loss: 0.0279, Train Acc: 0.9899 (16.06s) | Val Loss: 0.0416, Val Acc: 0.9866 (2.19s)\n",
      "Epoch 6/15 | Train Loss: 0.0240, Train Acc: 0.9913 (18.50s) | Val Loss: 0.0358, Val Acc: 0.9892 (2.43s)\n",
      "Epoch 7/15 | Train Loss: 0.0199, Train Acc: 0.9927 (17.64s) | Val Loss: 0.0417, Val Acc: 0.9870 (2.44s)\n",
      "Epoch 8/15 | Train Loss: 0.0172, Train Acc: 0.9937 (17.05s) | Val Loss: 0.0395, Val Acc: 0.9868 (2.45s)\n",
      "Epoch 9/15 | Train Loss: 0.0169, Train Acc: 0.9939 (18.80s) | Val Loss: 0.0388, Val Acc: 0.9888 (2.10s)\n",
      "Epoch 10/15 | Train Loss: 0.0140, Train Acc: 0.9948 (16.22s) | Val Loss: 0.0435, Val Acc: 0.9877 (2.16s)\n",
      "Epoch 11/15 | Train Loss: 0.0136, Train Acc: 0.9949 (15.58s) | Val Loss: 0.0441, Val Acc: 0.9884 (2.21s)\n",
      "Epoch 12/15 | Train Loss: 0.0124, Train Acc: 0.9952 (18.71s) | Val Loss: 0.0441, Val Acc: 0.9876 (2.23s)\n",
      "Epoch 13/15 | Train Loss: 0.0109, Train Acc: 0.9959 (17.65s) | Val Loss: 0.0448, Val Acc: 0.9884 (2.26s)\n",
      "Epoch 14/15 | Train Loss: 0.0097, Train Acc: 0.9961 (15.40s) | Val Loss: 0.0545, Val Acc: 0.9852 (2.35s)\n",
      "Epoch 15/15 | Train Loss: 0.0084, Train Acc: 0.9971 (18.91s) | Val Loss: 0.0439, Val Acc: 0.9888 (2.35s)\n",
      "\n",
      "--- Training Finished ---\n",
      "Total Training Time (ImprovedCNN_Q2): 293.43s\n",
      "Average Epoch Time (ImprovedCNN_Q2): 19.56s\n",
      "\n",
      "--- Evaluating ImprovedCNN_Q2 on Test Set ---\n",
      "Test Loss (ImprovedCNN_Q2): 0.0475\n",
      "Test Accuracy (ImprovedCNN_Q2): 0.9882\n",
      "Test Evaluation Time (ImprovedCNN_Q2): 2.12s\n"
     ]
    }
   ],
   "source": [
    "# Training Hyperparameters\n",
    "NUM_EPOCHS_Q2 = 15\n",
    "MODEL_NAME_Q2 = \"ImprovedCNN_Q2\"\n",
    "\n",
    "print(f\"--- Training {MODEL_NAME_Q2} for {NUM_EPOCHS_Q2} epochs ---\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Optimizer: {type(optimizer_q2).__name__} (LR={optimizer_q2.defaults['lr']})\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")\n",
    "print(f\"Dropout rate: {q2_model.dropout.p}\")\n",
    "\n",
    "# History Tracking  \n",
    "history_q2 = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'epoch_time': []\n",
    "}\n",
    "\n",
    "total_train_start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS_Q2):\n",
    "    train_loss, train_acc, train_time = train_one_epoch(\n",
    "        q2_model, train_loader, criterion, optimizer_q2, device\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc, val_time = evaluate(\n",
    "        q2_model, val_loader, criterion, device\n",
    "    )\n",
    "\n",
    "    # Record history\n",
    "    history_q2['train_loss'].append(train_loss)\n",
    "    history_q2['train_acc'].append(train_acc)\n",
    "    history_q2['val_loss'].append(val_loss)\n",
    "    history_q2['val_acc'].append(val_acc)\n",
    "    history_q2['epoch_time'].append(train_time + val_time)\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS_Q2} | \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} ({train_time:.2f}s) | \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f} ({val_time:.2f}s)\")\n",
    "\n",
    "total_train_end_time = time.time()\n",
    "total_training_time_q2 = total_train_end_time - total_train_start_time\n",
    "avg_epoch_time_q2 = sum(history_q2['epoch_time']) / NUM_EPOCHS_Q2 if NUM_EPOCHS_Q2 > 0 else 0\n",
    "\n",
    "print(f\"\\n--- Training Finished ---\")\n",
    "print(f\"Total Training Time ({MODEL_NAME_Q2}): {total_training_time_q2:.2f}s\")\n",
    "print(f\"Average Epoch Time ({MODEL_NAME_Q2}): {avg_epoch_time_q2:.2f}s\")\n",
    "\n",
    "# Evaluate Final Model on Test Set\n",
    "print(f\"\\n--- Evaluating {MODEL_NAME_Q2} on Test Set ---\")\n",
    "test_loss_q2, test_acc_q2, test_time_q2 = evaluate(\n",
    "    q2_model, test_loader, criterion, device\n",
    ")\n",
    "print(f\"Test Loss ({MODEL_NAME_Q2}): {test_loss_q2:.4f}\")\n",
    "print(f\"Test Accuracy ({MODEL_NAME_Q2}): {test_acc_q2:.4f}\")\n",
    "print(f\"Test Evaluation Time ({MODEL_NAME_Q2}): {test_time_q2:.2f}s\")\n",
    "\n",
    "# Store test results\n",
    "history_q2['test_loss'] = test_loss_q2\n",
    "history_q2['test_acc'] = test_acc_q2\n",
    "history_q2['test_time'] = test_time_q2\n",
    "history_q2['total_train_time'] = total_training_time_q2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syde",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
